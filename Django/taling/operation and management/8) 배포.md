## 배포

## CI/CD


### CI
- Continuous Integration의 약자로 "지속적인 통합"이라는 뜻이다. 즉, 우리가 소스코드를 작성한 다음에 github과 같은 레포지토리에 코드를 올려두면, 원하는 타이밍에 자동으로 소스코드가 빌드되고 테스트까지 수행되는 것을 CI라고 한다.
- CI와 관련해서 여러 툴들이 있는데, 
  - Github Action : 깃헙의 내부 서비스 기능으로, 소스코드를 git에 올려두면 자동으로 인식해서 소스코드를 내려받아 빌드를 수행하고 패키징을 해서 이후 배포를 위해 빌드 버전별로 CD에서 가져갈 수 있는 위치에 업로드까지 수행해준다. 필요하다면 이 과정에서 유닛 테스트 통과 여부도 같이 수행하고 실패하면 빌드를 진행하지 않는 과정도 거친다. 즉, github 레포지터리를 기반으로 빌드, 테스트, 배포 이벤트를 발생 시킬 수 있다. 예전 인터프리터형 코드는 단순 파일 압축 형태로 / 빌드가능한 언어들은 빌드결과물만 아카이빙해서 versioning을 했다면 -> 요즘에는 Docker 이미지 기반으로 결과물을 생성하고 있다.

### CD
- Continuous Delivery & Deployment의 약자로 "지속적인 전달과 배포"라는 뜻이다. 즉, 그리고 그렇게 빌드된 프로그램이 자동으로 버전이 올라가서 실제 사용자에게 배포까지 자동으로 나가는 과정을 CD라고 한다.
- CD와 관련해서도 여러 툴들이 있는데,
  - 이렇게 빌드된 Docker 이미지를 AWS ECS라는 CD 툴을 사용해서 EC2에 배포하는 것으로 구현할 수 있다. AWS Code Deploy와 같은 툴도 제공하고 있다. 버전에 따라 선택하려는 툴이나 상세 설정 값에 따라서 배포 세팅이 다양해지기도 하고 최신 트렌드까지 고려하면 쿠버네티스를 포함하는 다른 파트를 좀 많이 배워야 할 정도로 양이 많기에 실습을 하기는 어렵다.


### 꼭 알아야 할 기술
- **Github Action**
  - 요새는 Github에 코드를 많이 올려서 사용하는데, 그래서 Github Action이라는 메뉴가 있다. 거기에 내가 스크립트를 작성해서 스크립트를 넣어주면 그것에 따라서 테스트를 하거나 아니면 github에서 master 브랜치에다가 코드를 merge 하는 순간에 자동으로 빌드를 트리거링 해가지고 github이 알아서 어떤 동작을 수행하게끔 할 수 있다. 


- **Docker**
  - 리눅스 기반의 실행환경과 프로그램을 "컨테이너"라는 개념으로 격리시켜서 컨테이너 단위로 시스템을 구동하고 프로그램을 실행시킬 수 있게 해주는 오픈소스 프로젝트이다. 그래서 빌드 명령이 시작되면 Docker 기술을 통해 컨테이너 이미지(Django 웹앱과 필요한 패키지, 시스템 구성요소들을 전부 그대로 하나의 리눅스 서버로 실행할 수 있는 패키지로 묶음)가 생성
  - 이게 버튜얼 머신이나 부트캠프 같은 것을 써본 사람들은 이해할 수 있다. **Docker는 가상화 기술을 이용해서 마치 사진을 찍듯이 컴퓨터 상태, 그러니까 설치된 프로그램이나 OS, 파일 그대로 "식품을 얼려서 보존하듯이" 스냅샷으로 보존을 해준다.** 그리고 이걸 복제를 그대로 할 수 있게 해준다. 그래서 복제를 해서 필요할 때마다 해동해서 뭔가를 꺼내 쓰는 것 처럼, 그 이미지 상태와 똑같은 컴퓨터를 막 찍어낼 수 있도록 해주는 것을 "Docker 라이징"이라고 한다. 그리고 이 Docker 라이징의 결과물로 Docker 이미지가 만들어진다. 그래서 우리가 Docker 이미지를 가지고 있으면 서버를 여러개로 막 찍어낼 수 있는 것이다.


- **AWS ECS**
  - CD에 대표적인 사례라고 볼 수 있다. AWS의 컨테이너 오케스트레이션(인프라나 시스템 자원을 조정하는 걸 자동화하는 시스템)으로 컨테이너 기반으로 서버 및 인프라를 구동하고 증설하거나 축소하는 등의 기능을 의미. Github Action에서 merge가 되서 빌드라는 이벤트가 발생하면 -> Docker 이미지라는 게 만들어지고 -> 그 이미지를 이 AWS ECS에서 가지고가서 EC2 서버를 띄울 때 사용한다. 이게 바로 CD 즉, Delivery와 Deployment의 개념이 된다. 
  - 그렇게 해서 배포가 될 때, 사용량에 따라서 자동으로 배포를 자동화해주고 또한 그 과정에서 무중단 배포를 해준다거나 별도의 증설, 서버를 1대만 띄울 수 있지만 배포할 때 한 번에 20대, 100대 이렇게 할 수도 있다. 그래서 그걸 자동화해서 조정을 해준다는 개념이다. 그래서 오케스트레이션이라는 단어가 등장한다. 

- 여기 설명된 툴 이외에도, CI/CD를 통합해서 가지고 있는 툴들도 많고 하나만 가지고 있는 툴들도 많다. 대표적으로는 Jenkins, GoCD, TravisCI, TeamCity, CircleCI 등이 있다. 
- 더 자세히 배우고 싶다면 "쿠버네티스" 나 "데브옵스"에 대해서 따로 공부하면 좋을듯 하다.


### MSA(Micro Service Architecture)
- 우리가 백엔드 프로젝트를 만들 때 Web 앱을 Web과 Office로 2개의 App으로 쪼개서 구현을 했다. 이렇게 2개로 쪼갰을 때 각각을 다른 서버, 다른 클러스터로 구성해서 하는 것도 방법이지만 더 작게 쪼개서 Web에서도 사용자 관련 기능, 예약 관련 기능, 식당 관련 기능으로 나눠서 서비스를 개발하고 개별적으로 배포할 수 있도록 구성하는 것을 의미하기도 한다. 이게 바로 MSA이다. 
- 최근에는 하나의 서비스가 워낙 커지고 있기 때문에 하나의 서비스가 단일 프로젝트로 완성되는 것 보다는 여러 프로젝트로 나눠서 각자 역할을 분담해서 구현하게 된다. 
- 만약에 우리가 쇼핑몰을 구현한다면, 검색단만 만드는 프로젝트가 있고, 해당 프로젝트를 담당하는 조직이 그대로 일대일로 대응되는 형식이 있는 것이다. 만약에 쇼핑몰이 작다면 상관이 없지만, 아마존/쿠팡/이베이/네이버쇼핑/11번가/G마켓 이런 큰 마켓의 경우에는 시스템이 워낙 크기 때문에 하나의 기능 단위에서 해결해야 하는 작업도 너무 많아서 MSA로 구성하지 않으면 조직을 나누기도 어렵다. 또한 각각의 프로젝트의 버전 추적이나 장애 원인 파악도 너무 어려워지게 된다. 
- 예를 들자면, 쇼핑몰 개발이 만약 하나의 거대 단일 시스템으로 되어있다면 -> 검색 기능을 고칠때마다 사용자기능, 관리자 기능 등 같이 배포가 한꺼번에 도매급으로 이루어지게 될 것이다. 이렇게 검색기능을 고치는 와중에 사용자 관련 기능 코드를 수정하게 될 수도 있어서 side effect를 전파할 가능성이 있다. 
- 그리고 하나의 배포에 대해서 이곳 저곳에서 업데이트한 내역들이 막 합쳐져서 한 번에 나가기 때문에, 만약 그 이후에 장애가 발생했다면 원인을 파악하려면 관련된 모든 담당자나 조직들이 자신의 문제가 아닌지 어떤 문제가 있는지 찾아봐야 하는 번거로움이 생긴다. 
- 그래서 이러한 MSA라는 개념 덕분에 -> 조직별로 필요한 단위로 쪼개서 서비스를 운영하고 / 배포를 할 수 있게 되었다. 이에 따라 배포 방식에 대한 고민도 따라오게 되었다. 


### 배포의 종류
- **롤링 배포(Rolling)**
  - 새로운 배포가 발생할 때 이전 버전의 서버를 종료하고 신규 버전의 서버를 구동한 뒤 트래픽을 받는 방식이다. 
  - 구성방법은, 기존의 서버 여러 개가 하나의 클러스터를 이루고 있고 / 요청이 분산되서 각각 서버들에게 들어오고 있었는데, 우리가 서버 배포를 시작한다라고 했으면 서버 여러 개 중 1개를 죽이고 새로운 서버가 뜬다. 이렇게 계속 서버를 1개씩 롤링시키면서 새로운 서버로 교체해 나가는 것을 롤링 배포라고 한다. 그리고 하나의 클러스터 내에서 이 과정이 이루어지게 된다. 
  - 이 롤링 배포의 문제점은, 요청이 분산되어 들어올 때 A라는 사용자가 접속할 때마다 다른 결과가 나올 수가 있다. 왜냐면, 특정 시간대를 짤라서 보면, 하나의 클러스터에 버전1에 해당하는 서버가 x모양으로 4개가 있고 / 버전2에 해당하는 서버가 네모모양으로 3개가 있다고 하자. 이 때 A가 요청을 보낼 때 어떨때는 버전2로 가고 어떨때는 버전1으로 갈 것이다. 그러다보니까 데이터가 꼬이게 된다. 그래서 응답 결과가 다르게 나올 수가 있다는 것이다. 그리고 껏다가 켜질때마다 장애가 생길 수 있는, 서비스의 순단이 생길 수 있다.
  - 예를 들어 서버 1대, 단일 서버가 있을 때 이걸 롤링 배포를 적용한다고 생각해보자. 그러면 요청이 막 여러 번 들어오고 있는데, 중간에 이걸 꺼버리고 새로운 서버를 띄우게 될 것이다. 그러다보니까 이렇게 새로운 서버로 전환되는 시점에 요청이 들어오는 얘들은 전부 다 블로킹이 되어버린다. 그래서 서버에 접속이 되지 않는다. 이런 상황이 순단이 된다. 
  - 그리고 MSA 구조를 실무에서 사용하게 되면서 롤링 배포보다는 블루그린 / 카나리 배포 전략들이 사용되기 시작했다. 


- **블루 그린 배포(Blue-Green)**
  - 블루 그린 배포는 클러스터를 2개를 만들어두었다. 그래서 하나는 블루존이고 하나는 그린존이다. 블루존에 버전1의 서버가 여러 개 들어가 있고 배포를 시작하게 되면, 버전2를 그린존에다가 같은 개수의 버전2 서버들을 실행하게 한다. 그래서 그린존에서 미리 헬스 체크를 다 해본다. 이 체크를 통과하면 -> 트래픽을 앞에 라우터 / 로드 밸런서 단에서 블루존으로 부어주고 있다가 헬스 체크가 통과되면 -> 블루존을 끊고 그린존으로 넘겨주는 것을 블루 그린 배포라고 한다. 이 방식은 순단이 거의 발생하지 않는다. 왜냐면 클러스터 단위로 수행을 하기 때문에 1대에만 있는 클러스터라도 2개의 클러스터를 구축해서 그린존이 잘 뜨는 것이 확증이 되었을 때 트래픽을 넘기기 때문이다.
  - 즉, 무중단 배포의 일종으로 신규 버전의 서버 클러스터를 구동 후 구버전 서버로 들어오는 트래픽 방향을 신규 버전이 정상적으로 헬스체크가 완료되었을 때 자동으로 신규 서버의 클러스터로 전환하고 전부 트래픽이 넘어간 시점에 구버전 서버 클러스터를 종료하는 방식이다. 


- **카나리 배포(Canary)**
  - 클러스터 2개가 있고 왼쪽에는 버전1의 클러스터가 있고 / 오른쪽에는 버전2의 클러스터가 있는데 -> 사용자들의 요청들을 확률적으로 보내는 것이다. 그래서 버전1으로 트래픽을 보내고 있다가 요청이 4분의 1 확률로 버전2로 가게 되는 것이다. 
  - 우리가 어떤 서비스를 운영하고 있는데 사용자가 10만명이라고 가정을 해보면, 10만명 중에서 4분의 1인 25,000명은 미리 신규 버전 서버로 보내서 버전2의 서버가 런타임 오류는 없는지 미리 체크하게 하는 것이다. 그래서 만약 장애가 발생했다고 하더라도 75,000명은 장애를 겪지 않고 25,000명만 장애를 겪는 상황이 된다. 그래서 우리가 미리 장애를 감지해서 오류가 난다고 하면 다시 롤백을 해가지고 버전1으로 돌릴 수 있다. 이러면 오류대응이 손쉬워 지기도 하고 장애가 생겼을 때 장애를 겪는 사용자 수가 확연하게 감소하게 된다. 예로는 4분의 1이지만 실제로는 20분의 1, 100분의 1, 1000분의 1로 트래픽을 보내게끔 구현하는 경우가 많다.
  - 그리고 먼저 100분의 1로 테스트를 해본 뒤에 100분의 2... 이런식으로 퍼센트 확률을 올려보는 것도 카나리 배포의 일종이기도 하다. 그래서 이렇게 트래픽을 비율로 조정해서 전환해 나가는 것을 카나리 배포라고 보면 된다.
  - 즉, 무중단 배포의 일종으로 신규 버전의 클러스터를 구동 후 일부의 적은 트래픽만 신규 버전의 서버로 받은 상태로 두어 서비스 장애 여부를 모니터링 하다가 오류가 발생하지 않으면 순차적으로 수동으로 트래픽을 100% 신규버전 쪽으로 전환해 나가는 방식의 배포를 의미한다. 



### 실습으로 CI 세팅해보기
- 이제 우리가 만든 django 웹 앱을 서비스로 띄울 때, 우리 프로젝트를 읽어서 CI가 Docker 이미지를 생성할 수 있도록 우리 프로젝트에 Docker 파일을 만들어보고 우리 컴퓨터에서 실제로 실행시켜보는 실습을 진행해보자. 
- 먼저 Docker를 컴퓨터에 설치해야 한다. 바탕화면에 "Docker 설치법" 텍스트 파일을 참고해서 설치 진행. 그래서 터미널에 docker라고 입력하면 docker 명령어를 실행할 수 있는 상태가 되면 된다.
- **table_bookings 디렉터리의 상위 디렉터리 내부에다가 "Dockerfile"이라고 파일을 만든다. 그래야 나중에 CI/CD에서 이 파일을 읽어가게 된다.**
  - 그리고 해당 파일 내부에 코드를 작성해준다.

```Dockerfile
FROM python:3.9
ENV PYTHONUNBUFFERED 1
WORKDIR /app
COPY requirements.txt /app/
RUN pip install -r requirements.txt
COPY table_bookings/. /app/
EXPOSE 8000
CMD [ "python3", "manage.py", "runserver", "0.0.0.0:8000" ] 
```

- 위의 코드에서 앞에 있는 주황색 부분은 전부 Docker 명령어라고 보면 된다. 이건 Docker 문서에도 나와있다. 
- python 3.9버전으로 이미지를 빌드한다는 뜻이다. 즉, 3.9버전을 사용한다는 의미이다.
- 그 다음에는 ENV PYTHONUNBUFFERED 1 이 코드는 -> python의 플래그를 쓰지 않으면 로그가 python 출력이 밀려서 나오게 된다. 그래서 python 실행환경에서 보통은 우리가 의식하지 않아도 PYTHONUNBUFFERED 1이라는 환경변수가 세팅이 되어있는데, 지금은 우리가 컴퓨터를 새롭게 이미지로 만드는 과정이기 때문에 직접 이걸 선언해줘야 한다. 이렇게 하면 이 도커 파일을 통해서 생성된 서버는 python 3.9로 구동이 되면서 PYTHONUNBUFFERED 플래그가 설정된 상태로 실행이 되게 된다. 그렇게 된다는 것은 -> python에서 출력을 할 때, 로그나 이런 데이터들을 콘솔에 출력할 때 이 환경변수가 있기 때문에 밀리지 않는다. 이게 없으면 버퍼링을 계속 하게되서 한 타임씩 늦게 뜬다. 
- 그 다음 WORKDIR /app 이렇게 해서 app이라는 폴더에서 시작하게끔 한다. 그리고 COPY requirements.txt /app/ 이렇게 해서 txt 파일을 복사해서 app 폴더 안에다가 넣어준다. 
- RUN pip install -r requirements.txt 그리고 이 코드로 python안에다가 install 하겠다는 것. txt 파일을 적용하겠다는 것이다. 
- COPY table_bookings/. /app/ -> 이렇게 해서 table_bookings 내부에 있는 파일들을 전부 app에 옮긴다. 
- EXPOSE 8000 -> 지금 이렇게 뜬 서버의 포트를 8000번 포트를 노출시켜준 다음에 
- CMD [ "python3", "manage.py", "runserver", "0.0.0.0:8000" ]  -> 커맨드에 python3를 직접 호출해서 manage.py를 실행시켜준다. 이 때 runserver라는 인자를 넘겨주고 그 다음 인자로 0.0.0.0:8000를 넘겨주어서 누구나 8000번 포트에 접속하게끔 한다.
  - EXPOSE 8000까지는 -> 서버와 관련된 작업들이다. 그러니까 마치 리눅스나 우분투에서 명령어를 치듯이 이렇게 실행이 되는 것이다. 
  - 그 다음 마지막 CMD.. 는 -> 서버 포트를 오픈하고 python를, 즉 우리의 웹 앱을 실행시키는 마지막 커맨드를 입력하는 과정이 된다.

- 이제, Dockerfile이 내부에 있는 디렉터리 위치로(즉, ls를 했을 때 Dockerfile이 있는 위치)가서 

```terminal
docker build . -t docker-django
```

- 이렇게 명령어를 입력해준다. 그러면 docker 이미지 빌드가 시작된다. 그러면 우리가 입력한 명령어대로 순서대로 실행이 된다. 
- docker build 다음으로 한칸 띄고 점을 입력해줘야 한다. 보통 docker build 명령어 다음으로 경로를 지정하는 것인데 그래서 점으로 현재 경로를 지정한 것이다. 현재 경로에 Dockerfile이 있어야지 해당 명령어가 수행된다. 그리고 t라는 옵션을 줘서 docker 이미지의 이름을 docker-django로 정한것이다. 
  - **그래서 EXPOSE 전까지는 이미지로 묶이게 되고 / EXPOSE부터는 docker 이미지가 실행 되었을 때 구동되는 방식을 정의한 것으로 보면 된다.**

- 그 다음은,

```terminal
docker images

REPOSITORY      TAG       IMAGE ID       CREATED         SIZE
docker-django   latest    266fc56a599e   2 minutes ago   1.04GB
```

- 해당 명령어를 입력해서 이미지가 생성되었는지를 확인해볼 수 있다. 그러면 이렇게 생성된 걸 볼 수 있다. 그리고 대략 1GB가 된다.
- 그리고 이걸 실행시켜 보려면,

```terminal
docker run -d -p 8080:8000 docker-django

845d7d9707565f351f5ae589fa7250e29a059cc30c034b28226a6871294f8c59
```

- 이렇게 입력해주면 된다. **docker run를 하고 p라는 옵션이 포트 포워딩을 해주는 부분이다.** 우리가 위해서 코드로 8000번 포트로 서버를 띄운다고 정리를 해놓았다. 그래서 8000번 포트를 노출시켰다. 그래서 서버가 실행될 때 8000번 포트가 뜰 것이다. 그리고 서버가 뜨면 CMD [ "python3", "manage.py", "runserver", "0.0.0.0:8000" ]  -> 이렇게 우리가 python으로 runserver를 8000번 포트로 하겠다 이 얘기를 한 것이다. 
- 그러면 지금 이 이미지를 통해서 실행되고 있는 서버는 8000번 포트로 실행이 되고 있을 것이다. 그래서 만약 터미널에 -p 8000:8000 이렇게 하면 -> docker-django를 통해서 서버 하나가 뜨는데 그 서버가 뜰 때 8000번 포트로 접근하면 그대로 8000번 포트로 요청이 들어오게 될 것이다. 
- **근데 이걸 바꿔서 -p 8080:8000 --> 이렇게 하면 8080포트로 접근했을 때 / 8000번 포트로 이동해서 꽂히게 된다.**
- 위의 명령어를 그래서 입력하면 16진수로된 문자열이 뜨게 된다. 
  - 그 다음 우리가 브라우저에서 127.0.0.1:8080을 입력하게 되면 -> 
