## 로드밸런싱과 SSL
- 서버의 스케일 아웃을 어떻게 처리할까. 많은 서버가 요청을 받을 때 HTTP 요청이 들어오게 되면, 어떻게 하나의 서버로 지정되어 포워딩 되는 걸까.
- 우리가 은행을 방문하는 걸 생각해보자. 그럼 보통 문에 번호표가 있다. 번호표를 뽑고 숫자를 확인하고 창고에서 해당 번호가 될 떄까지 기다렸다가 번호가 뜨면 은행업무를 보려가게 된다. 

- **트래픽의 분산도 이와 유사하다.**
  - **여기서 번호표를 제공하는 역할을 하는 것을 "로드 밸런서"라고 한다. HTTP 요청이 들어오면 웹 앱 서버로 트래픽을 분산해서 포워딩해주는 역할을 한다.** 그리고 이런 개념을 로드 밸런싱이라고 한다. 


### 로드 밸런서의 종류
- **L4: IP/Port**
  - 컴퓨터의 네트워크 레이어(Layer) 레벨을 따서 4번 계층인 Transport 레이어 단위에서 분산을 하면 L4

- **L7: URL/HTTP Header**
  - 7번 계층인 어플리케이션 레이어 단위에서 분산을 하면 L7이라고 한다.

- "네트워크" 부분에서 Transport Layer와 Application Layer를 공부해보자. 
   - L4는 우리가 어떤 호스트를 입력하고 들어왔을 때 들어온 IP별로 .... 일반적인 하드웨어 단에서의 로드 밸런서가 보통 여기에 속한다. 네트워크 Transport Layer단에서 패킷들이 데이터가 왔다갔다 한다. 그 때 Transport Layer단에서 인식할 수 있는 태그들이 있다. 그게 바로 하나가 IP이고 Port번호도 있다. 그래서 이러한 Port 번호들을 인식할 수 있으니까 이 Port 번호가 80번이면 어디로 보내고, 81번이면 여기로 보내고 이렇게 할 수 있다. 80번으로 보냈을 때 80번은 포워딩을 내부 클러스터에 8080으로 보낸다거나, 즉 도커처럼 80번으로 들어왔을 때 -> 8080포트로 보낸다거나 이런식의 포워딩을 해주는 것이 L4가 하는 역할이다.  
   - L7은 이 패킷 단위에서 더 쪼개가지고 이걸 해석한 뒤에 HTTP 메시지로 까보는 것이다. 여기에 보통 Header들이 들어있으니까, GET이나 POST나 이런것들도 담겨있고 path도 들어가 있을 것이다. /user 나 /search 등 이런 path들을 다 측정을 해서 이것에 따라서도 포워딩을 다르게 할 수 있는 것을 application Layer의 로드 밸런서라고 해서 L7이라고 부른다. 


### 로드 밸런서 알고리즘
- 그리고 분산 처리시의 어떤 서버의 요청을 포워딩하느냐에 따라서 알고리즘을 크게 3가지로 구분할 수 있다. 

- **라운드 로빈**
  - 만약, 3대의 서버 컴퓨터가 있다고 하면 요청이 들어올 때 이 컴퓨터를 순서대로 전달하는 알고리즘이다. 즉, 순차적으로 서버에 돌아가며 포워딩을 한다. 그래서 3대의 번호가 1/2/3이라면 계속 1/2/3/1/2/3/... 이러한 순서대로 포워딩을 하게 된다. 

- **웨이티드 라운드 로빈**
  - 이건 특정 서버에 가중치를 부여하여 배분되는 비중을 달리하는 방법이다. 그래서 보통 하나의 서버가 TPS(Transaction Per Second로 '초당 트랜잭션 수' 또는 '1초에 처리하는 단위 작업의 수'를 의미)가 많이 나와서, 처리량이 많아서 2번씩 보내게 된다. 그래서 1/2/3/3/1/2/3/3/... 이렇게 3번 서버에만 2번씩 보내게 된다. 

- **리스트 커넥션**
  - 최소 연결 수 서버에 우선적으로 포워딩하는 것을 의미한다. 서버 컴퓨터 1,2,3이 있고 요청이 1번에 5개, 2번에 4개, 3번에 1개 이렇게 보내지고 있다면 3번 서버가 제일 적기 때문에 -> 3번에 우선적으로 배분해서 요청을 보내는 것이다. 이런식으로 커넥션을 체크해서 보내는 방식이다. 보통은 이 커넥션 타임이 길지 않은 웬만한 서버들의 경우에는 라운드 로빈으로 처리를 한다. 



### AWS 로드 밸런서 
- 로드 밸런서를 실제로 실습하기 위해 AWS 로드 밸런서를 사용해서 구현을 할 것이다. 여기 AWS 로드 밸런서에서는 도메인을 연결하고 SSL 인증서라는 것을 연결하면 사용자가 HTTPS로 접속할 수 있도록 하는 게 가능하다.


### SSL(Secure Sockets Layer) 인증서
- SSL 인증서를 알기 위해서는 먼저 다음의 내용을 알고 있어야 한다.

- **공개키/개인키 암호화**
  - RSA 알고리즘이 유명하며 개인키로 암호화하면 공개키로만 복호화가 가능한 특징이 있다. 
  - ex) 우리가 편지를 보낸다고 생각해보자. 그래서 공개키, 공개열쇠를 봉투에 같이 넣어서 수신자한테 보냈다. 수신자가 메세지를 받았고 그 내용을 공개키로 까보는 것이다.(공개키를 제3자가 들고 있다.) 그러면 복호화가 잘 되어서 의미있는 문장이 되었다. 사실 내가 편지를 작성할 때 개인키가 있고 암호표가 있다. 그래서 이 암호표를 가지고 내가 메세지를 작성해서 개인키로 암호화를 하는 것이다. 이렇게 공개키로 복호화가 가능하려면 숨겨진 개인키로 암호화를 해야지만 가능하다는 특징이 있다. 이런식으로 만들어진 게 바로 RSA 알고리즘이다. 즉, 특정 키로는 암호화만 되고 특정 키로는 복호화만 되는 특징을 이용한 것이다.


- **CA(인증기관)**
  - 인증서를 발급하는 기관으로 암복호화를 위한 공개키와 개인키도 발급한다. 그래서 위에서 언급한 제3자가 바로 CA이다. 
  - CA가 있고, 서버와 클라이언트가 있다고 생각해보자. 그래서 서버가 CA한테 인증서를 발급해달라고 한다. 그러면 CA가 인증서를 발급해주면서 서버한테 개인키를 몰래 준다. 그리고 CA는 공개키를 진열대에 올려둔다. 그래서 누구나 가지고 갈 수 있게 한다. 그래서 클라이언트가 와서 해당 공개키를 가져갈 수 있는 것이다. 그 클라이언트가 서버와 통신을 할 때 -> 서버의 개인키로 암호화된 메세지를 클라이언트가 받아서 공개키로 복호화를 해서 내용을 확인할 수 있는 것이다. 
  - **이렇게 하면 통신할 때 암호화가 유지된다. 만약 중간에 다른 해커가 있어서 네트워크를 해킹해서 클라이언트가 접속을 해커랑 할 수도 있다. 이게 바로 "피싱"이라는 것이다.** 예를 들어서 나는 분명히 특정 은행 사이트에 접속했는데 이상하게 해커 사이트로 가게 된다. 근데 화면은 똑같이 생겼다. 그래서 비밀번호를 입력하게 만들어버렸다. **이 때 보면 -> url에 https가 아닐 것이다. 아마 s가 안 붙어있을 것이다.** 왜냐면 이 https를 정확하게 구현해서 메세지를 보낼 수 있는 주체는 올바른 서버밖에 없다. 해당 서버만 메세지를 나만의 숨겨진 키로 암호화해서 보낼 수가 있는데, 중간에 해커가 가로채고 있으면 얘는 이걸 개인키가 없으니까 흉내낼 수 없다. 
  - **그래서 보통 피싱 사이트인지 아닌지 보고 싶으면 -> url에 https가 뜨는지 안 뜨는지 확인하면 된다.** 이런 걸 지원해주는 것이 바로 https와 SSL 인증서이다.


- **TLS**
  - SSL 3.0 버전부터는 TLS라는 명칭을 사용한다. 


### SSL 연결 수립(바탕화면 참고)
- 클라이언트와 서버가 연결 수립을 하는 과정이다.
- 처음에는 TCP로 "3 way 핸드쉐이크"라는 걸 한다.(둘이 악수를 한다는 의미) 클라이언트와 서버가 서로 연결을 수립하기 전에 연결의 패킷을 맞춰보는 작업을 하는 것이다. 
- 이렇게 해서 연결이 수립이 되면, 그 다음에는 TLS로 say hello해서 인증서를 체크하고 인증서에서 인증서 교환을 하고, 키를 교환하고 암호화 스펙을 공유한다. 
- (검정색 부분)그리고는 데이터를 그 다음부터는 암호화해서 왔다갔다 하는 로직을 타게 된다. 
  - **여기서 중요한 건, TLS까지 오면서 발전이 되긴 했다. 위에서 우리가 공개키로 까보고 체크한다고 했는데, 이제는 여기에 더해서 중간에 암호화 키를 교환하기도 한다. 중간에(TLS에서) 암호화 키를 생성한다. 그리고 우리가(서버가) 메세지를 보낼 때 이 암호화 키 자체를 한번 더 서버의 개인키로 암호화를 하는 것이다. 그래서 이걸 클라이언트한테 보내서 클라이언트가 이걸 까본다. 여기서 암호화 키를 꺼낼 수 있고 이 키를 가지고 서로 통신하는 것이다. 그러면 다시 RSA 방식으로 클라이언트는 본인의 암호화 키로(?) 암호화를 해서 다시 서버에 전송하는 것이다.**
  - 이런식으로 서버와 클라이언트 둘이 소통을 할 수 있는 서로의 암호화 키를 교환하게 된다. 매 연결마다 교환하게 된다. 이 암호화 키를 이용해서 서로의 일반적인 메세지들도 전부 다 암호화를 해서 종단 간 암호화를 완성시키는 것도 포함이 된다. 
  - 이렇게 TLS나 SSL 방식들은 공개키나 개인키 암호화를 사용해서 이런 인증서를 유효성 체크를 하고 그 키를 이용해서 서로의 이번 연결에 사용할 암호화 키를 교환 한 다음에 그 키를 이용해서 서로의 메세지를 해석하면서 데이터를 교류한다고 보면 된다.



### 아키텍처
- 지금까지 우리가 TCP 커넥션을 맺는 과정에서 SSL 통신을 수립하는 과정까지 확인을 해봤다. AWS도 CA역할이 가능하기 때문에 도메인 연결을 해보면서 AWS Certificate manager를 사용해서 실제 인증서 발급을 진행해보고 로드 밸런서를 세팅해보자.
- 우리가 설계할 아키텍처는 다음과 같다.(바탕화면 참고)
  - **여기에 보면 S3라는 것이 추가되었는데, 우리가 멀티 인스턴스 환경에서는 기존의 업로드 파일을 로컬에 저장하는 식은 파일의 n분의 1 확률로만 접근에 성공하게 된다. 그래서 중앙에 저장해둘 저장소가 필요하게 된 것이다.**  
  - 예를 들면, 첫번째 EC2 서버에서 오리 사진을 하나 올렸는데, 나중에 다른 요청이 들어와서 오리 사진을 조회해보니까 3번째 EC2 서버에는 없다. 오리 사진은 그냥 첫번째 서버의 파일로 안에만 생긴 것이기 때문이다. 이걸 방지하기 위해 멀티 인스턴스 환경에서는 오리 사진을 S3라는 공유 저장소에 올려두고 모든 EC2 서버가 접근할 수 있게 만드는 것이다. 


### S3 파일 업로그




